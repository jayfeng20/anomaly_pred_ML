{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the good old ScikitLearn library to normalize.\n",
    "\n",
    "Alternatively, we could use TensorFlow FeatureSpace to normalize data, but needs more time to validate this approach\n",
    "\n",
    "The advantage is consistency and clarity, as a more regulated and organized approach for distributed system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a demonstration for designing the featureSpace of pmcl = 764327358/01 for a classification NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv into a Pandas dataframe\n",
    "dataframe = pd.read_csv(\"dataset2.csv\")\n",
    "print(dataframe.shape)\n",
    "dataframe.head()\n",
    "\n",
    "# split the data into a training and validation set\n",
    "val_dataframe = dataframe.sample(frac=0.2, random_state=7491)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a DataFrame to a tf Dataset, last column being the label\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"FSR_Required\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn df into ds\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Dataset yields a tuple (features, target) where features is a dictionary of features and target is the value 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)\n",
    "for x, y in train_ds_autoencoder.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch them\n",
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of featureSpace design\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "\n",
    "        # Categorical feature encoded as string\n",
    "        \"cycle_type\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        # Categorical features encoded as integers\n",
    "        \"DLS_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORASW2_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORA_CLSD_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORA_PLK_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORA_SEAL_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORB_PLK_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORB_SEAL_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"NEUT1_SW_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"NEUT2_SW_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"NO_FLOOD_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S01_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S02_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S03_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S04_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S07_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S09_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S35_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S37_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S40_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S43_init\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DLS_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORASW2_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORA_CLSD_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORA_PLK_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORA_SEAL_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORB_PLK_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"DOORB_SEAL_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"NEUT1_SW_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"NEUT2_SW_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"NO_FLOOD_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S01_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S02_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S03_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S04_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S07_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S09_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S35_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S37_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S40_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"S43_end\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        # Numerical discretized features to normalize\n",
    "        \"cycle_duration\": FeatureSpace.float_discretized(num_bins=500),\n",
    "        # \"cycle_duration\": FeatureSpace.float_normalized(),\n",
    "        # Numerical features to normalize\n",
    "        \"DLS_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DOORASW2_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DOORA_CLSD_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DOORA_PLK_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DOORA_SEAL_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DOORB_PLK_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DOORB_SEAL_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"NEUT1_SW_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"NEUT2_SW_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"NO_FLOOD_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S01_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S02_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S03_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S04_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S07_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S09_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S35_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S37_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S40_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"S43_act_count\": FeatureSpace.float_normalized(),\n",
    "        \"DLS_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"DOORASW2_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"DOORA_CLSD_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"DOORA_PLK_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"DOORA_SEAL_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"DOORB_PLK_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"DOORB_SEAL_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"NEUT1_SW_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"NEUT2_SW_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"NO_FLOOD_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S01_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S02_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S03_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S04_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S07_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S09_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S35_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S37_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S40_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"S43_first_act\": FeatureSpace.float_normalized(),\n",
    "        \"RRTD_peak\": FeatureSpace.float_normalized(),\n",
    "        \"FXRES_peak\": FeatureSpace.float_normalized(),\n",
    "        \"GRTD_peak\": FeatureSpace.float_normalized(),\n",
    "        \"JRTD_peak\": FeatureSpace.float_normalized(),\n",
    "        \"TSENS_peak\": FeatureSpace.float_normalized(),\n",
    "        \"WRTD_peak\": FeatureSpace.float_normalized(),\n",
    "        \"CRTD_peak\": FeatureSpace.float_normalized(),\n",
    "        \"CPRES_peak\": FeatureSpace.float_normalized(),\n",
    "        \"RRTD_pit\": FeatureSpace.float_normalized(),\n",
    "        \"FXRES_pit\": FeatureSpace.float_normalized(),\n",
    "        \"GRTD_pit\": FeatureSpace.float_normalized(),\n",
    "        \"JRTD_pit\": FeatureSpace.float_normalized(),\n",
    "        \"TSENS_pit\": FeatureSpace.float_normalized(),\n",
    "        \"WRTD_pit\": FeatureSpace.float_normalized(),\n",
    "        \"CRTD_pit\": FeatureSpace.float_normalized(),\n",
    "        \"CPRES_pit\": FeatureSpace.float_normalized(),\n",
    "    },\n",
    "    # Specify feature cross with a custom crossing dim.\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(\n",
    "            feature_names=(\"cycle_duration\", \"cycle_type\"), crossing_dim=32\n",
    "        )\n",
    "    ],\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt feature space to the training data\n",
    "\n",
    "the FeatureSpace will:\n",
    "\n",
    "- Index the set of possible values for categorical features.\n",
    "\n",
    "- Compute the mean and variance for numerical features to normalize.\n",
    "\n",
    "- Compute the value boundaries for the different bins for numerical features to discretize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)\n",
    "\n",
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceate preprocessed training and validation set\n",
    "\n",
    "The tf.data API provides the tf.data.Dataset.prefetch transformation. It can be used to decouple the time when data is produced from the time when data is consumed. In particular, the transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. You could either manually tune this value, or set it to tf.data.AUTOTUNE, which will prompt the tf.data runtime to tune the value dynamically at runtime.\n",
    "\n",
    "--tensorflow documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_val_ds = val_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can construct your model based on the preprocessed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "# apply weights to alleviate the effects of imbalanced inputs\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
    "training_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=metrics)\n",
    "\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)\n",
    "\n",
    "training_model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
