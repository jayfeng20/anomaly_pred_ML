{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset preparation for pmcl = '764327358/01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import cycleFetch as cf\n",
    "import random\n",
    "from csv import DictWriter as dw\n",
    "from csv import DictReader as dr\n",
    "import csv \n",
    "import numpy as np\n",
    "from cycle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14554342', '14554351', '14554360', '14554368', '14554384', '14554408', '14554457', '14554458', '14554453', '14554469', '14554475', '14554502', '14554508', '14554524', '14554530', '14554548', '14554553', '14554579', '14554587', '14555564', '14650435', '14650892', '14652039', '14924290', '14925133', '14925828', '14928847', '14929766', '14931154', '14942392', '14943525', '14944579', '14946969', '14947867', '14951808', '14968788', '14925057', '14925231', '14935227', '14935557', '14942453', '14942628', '14943015', '14944081', '14944896', '14946975', '14947747', '14948679', '14949366', '14949671', '15011180', '15050624', '15056908']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# prepare metadata variables for later processing\n",
    "# prepare a metadata dictionary for faster metadata access\n",
    "\n",
    "metadata = ''\n",
    "metadata_dict = {}\n",
    "with open('full_data.json', 'r') as f:\n",
    "    metadata = list(json.load(f))[1]\n",
    "assert metadata['pmcl'] == '764327358/01', 'PMCL number incorrect'\n",
    "devices = metadata['devices']\n",
    "count = 0\n",
    "l = []\n",
    "for device in devices:\n",
    "    cycles = device['cycle_ids']\n",
    "    for i, cycle in enumerate(cycles):\n",
    "        \n",
    "        assert cycle['cycleId'] not in metadata_dict, 'Cycle duplicate found'\n",
    "        id = str(int(cycle['cycleId']))\n",
    "        d = {id: (cycle['starttime'], cycle['endtime'], cycle['duration'], 0)}\n",
    "        if ('FSR Required' in cycle):\n",
    "            d[id] = (cycle['starttime'], cycle['endtime'], cycle['duration'], 1) # set label\n",
    "            count += 1\n",
    "            l.append(id)\n",
    "        metadata_dict.update(d)\n",
    "\n",
    "print(l)\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample cycles\n",
    "# for pmcl = 764327358/01 first\n",
    "\n",
    "cycle_ids = []\n",
    "for device in devices:\n",
    "    # device_counter -= 1\n",
    "    device_id = device['deviceId']\n",
    "    # print(f\"Now executing device {device_id}\")\n",
    "    cycles = device['cycle_ids']\n",
    "    # cycle_counter = 50\n",
    "    # while (cycle_counter) > 0:\n",
    "    for cycle in cycles:\n",
    "        # cycle_counter -= 1\n",
    "        # while (cycle_counter > 0):\n",
    "            # cycle_counter -= 1\n",
    "        cycle_id = cycle['cycleId']\n",
    "        cycle_ids.append(cycle_id)\n",
    "\n",
    "# cycle_ids = random.sample(cycle_ids, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe digital/analog names and some other\n",
    "analog_set = set()\n",
    "digital_set = set()\n",
    "type_set = set(['GRAVITY', 'DART TEST', 'LEAK TEST', 'PREVAC', 'DART WARMUP'])\n",
    "sample = []\n",
    "for cycle in cycle_ids:\n",
    "    cycle_data = dict(cf.fetch_cycle_json(str(int(cycle))))\n",
    "    cycle_data = cycle_data['cycles'][0]\n",
    "    cur_type = cycle_data['cycle_type']\n",
    "    if cur_type in type_set:\n",
    "        type_set.remove(cur_type)\n",
    "        sample.append(cycle_data)\n",
    "    if len(type_set) == 0:\n",
    "        break\n",
    "    # type_set.add(cycle_data[\"cycle_type\"])\n",
    "    # print(cycle, cycle_data[\"cycle_type\"])\n",
    "    # for digital in cycle_data[\"ioevents\"]:\n",
    "    #     digital_set.add(digital['name'])\n",
    "    # analog = cycle_data['analog']\n",
    "    # for ts in analog:\n",
    "    #     for v in ts['values']:\n",
    "    #         analog_set.add(v['channelCode'])\n",
    "\n",
    "\n",
    "with open('sample.json', 'w') as f:\n",
    "    json.dump(sample, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle digital set: ['DLS', 'DOORASW2', 'DOORA_CLSD', 'DOORA_PLK', 'DOORA_SEAL', 'DOORB_PLK', 'DOORB_SEAL', 'NEUT1_SW', 'NEUT2_SW', 'NO_FLOOD', 'S01', 'S02', 'S03', 'S04', 'S07', 'S09', 'S35', 'S37', 'S40', 'S43']\n",
      "Analog channel set: set()\n",
      "Type set is set()\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cycle digital set: {sorted(['S43', 'NEUT2_SW', 'S09', 'S40', 'DOORB_PLK', 'NO_FLOOD', 'DOORASW2', 'DLS', 'DOORA_SEAL', 'DOORB_SEAL', 'NEUT1_SW', 'DOORA_CLSD', 'S35', 'S04', 'S37', 'S03', 'S02', 'S01', 'S07', 'DOORA_PLK'])}\")\n",
    "print(f\"Analog channel set: {analog_set}\")\n",
    "print(f\"Type set is {type_set}\")\n",
    "\n",
    "# Cycle digital set: {'S43', 'NEUT2_SW', 'S09', 'S40', 'DOORB_PLK', 'NO_FLOOD', 'DOORASW2', 'DLS', 'DOORA_SEAL', 'DOORB_SEAL', 'NEUT1_SW', 'DOORA_CLSD', 'S35', 'S04', 'S37', 'S03', 'S02', 'S01', 'S07', 'DOORA_PLK'}\n",
    "# Analog channel set: {'RRTD', 'FXRES', 'GRTD', 'JRTD', 'TSENS', 'WRTD', 'CRTD', 'CPRES'}\n",
    "# Type set is {'GRAVITY', 'DART TEST', 'LEAK TEST', 'PREVAC', 'DART WARMUP'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header the dataset .csv file that includes 98 features and 1 target label\n",
    "\n",
    "features = ['cycle_type', 'cycle_duration', \n",
    "            \n",
    "            'DLS_act_count', 'DOORASW2_act_count', 'DOORA_CLSD_act_count', \n",
    "            'DOORA_PLK_act_count', 'DOORA_SEAL_act_count', \n",
    "            'DOORB_PLK_act_count', 'DOORB_SEAL_act_count', 'NEUT1_SW_act_count', 'NEUT2_SW_act_count', \n",
    "            'NO_FLOOD_act_count', 'S01_act_count', 'S02_act_count', 'S03_act_count', 'S04_act_count', \n",
    "            'S07_act_count', 'S09_act_count', 'S35_act_count', 'S37_act_count', 'S40_act_count', 'S43_act_count',\n",
    " \n",
    "            'DLS_init', 'DOORASW2_init', 'DOORA_CLSD_init', 'DOORA_PLK_init', \n",
    "            'DOORA_SEAL_init', \n",
    "            'DOORB_PLK_init', 'DOORB_SEAL_init', 'NEUT1_SW_init', 'NEUT2_SW_init', \n",
    "            'NO_FLOOD_init', 'S01_init', 'S02_init', 'S03_init', 'S04_init', \n",
    "            'S07_init', 'S09_init', 'S35_init', 'S37_init', 'S40_init', \n",
    "            'S43_init', \n",
    "            \n",
    "            'DLS_end', 'DOORASW2_end', 'DOORA_CLSD_end', 'DOORA_PLK_end', \n",
    "            'DOORA_SEAL_end', \n",
    "            'DOORB_PLK_end', 'DOORB_SEAL_end', 'NEUT1_SW_end', 'NEUT2_SW_end', \n",
    "            'NO_FLOOD_end', 'S01_end', 'S02_end', 'S03_end', 'S04_end', \n",
    "            'S07_end', 'S09_end', 'S35_end', 'S37_end', 'S40_end', \n",
    "            'S43_end', \n",
    "\n",
    "            'DLS_first_act', 'DOORASW2_first_act', 'DOORA_CLSD_first_act', 'DOORA_PLK_first_act', \n",
    "            'DOORA_SEAL_first_act', \n",
    "            'DOORB_PLK_first_act', 'DOORB_SEAL_first_act', 'NEUT1_SW_first_act', 'NEUT2_SW_first_act', \n",
    "            'NO_FLOOD_first_act', 'S01_first_act', 'S02_first_act', 'S03_first_act', 'S04_first_act', \n",
    "            'S07_first_act', 'S09_first_act', 'S35_first_act', 'S37_first_act', 'S40_first_act', \n",
    "            'S43_first_act', \n",
    "            \n",
    "            'RRTD_peak', 'FXRES_peak', 'GRTD_peak', 'JRTD_peak', \n",
    "            'TSENS_peak', 'WRTD_peak', 'CRTD_peak', 'CPRES_peak',\n",
    "\n",
    "            'RRTD_pit', 'FXRES_pit', 'GRTD_pit', 'JRTD_pit', \n",
    "            'TSENS_pit', 'WRTD_pit', 'CRTD_pit', 'CPRES_pit',\n",
    "\n",
    "            'FSR_Required']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Cycle missing certain parts\n",
      "Writing Cycle 14652039 to csv ...\n",
      "registered 1th FSR cycle\n",
      "Writing complete. 3245/15286 done.\n",
      "Writing Cycle 14924290 to csv ...\n",
      "registered 2th FSR cycle\n",
      "Writing complete. 7737/15286 done.\n",
      "Writing Cycle 14925133 to csv ...\n",
      "registered 3th FSR cycle\n",
      "Writing complete. 7738/15286 done.\n",
      "Writing Cycle 14925828 to csv ...\n",
      "registered 4th FSR cycle\n",
      "Writing complete. 7739/15286 done.\n",
      "Writing Cycle 14928847 to csv ...\n",
      "registered 5th FSR cycle\n",
      "Writing complete. 7742/15286 done.\n",
      "Writing Cycle 14929766 to csv ...\n",
      "registered 6th FSR cycle\n",
      "Writing complete. 7743/15286 done.\n",
      "Writing Cycle 14931154 to csv ...\n",
      "registered 7th FSR cycle\n",
      "Writing complete. 7744/15286 done.\n",
      "Writing Cycle 14942392 to csv ...\n",
      "registered 8th FSR cycle\n",
      "Writing complete. 7748/15286 done.\n",
      "Writing Cycle 14943525 to csv ...\n",
      "registered 9th FSR cycle\n",
      "Writing complete. 7749/15286 done.\n",
      "Writing Cycle 14944579 to csv ...\n",
      "registered 10th FSR cycle\n",
      "Writing complete. 7750/15286 done.\n",
      "Writing Cycle 14946969 to csv ...\n",
      "registered 11th FSR cycle\n",
      "Writing complete. 7753/15286 done.\n",
      "Writing Cycle 14947867 to csv ...\n",
      "registered 12th FSR cycle\n",
      "Writing complete. 7754/15286 done.\n",
      "Writing Cycle 14951808 to csv ...\n",
      "registered 13th FSR cycle\n",
      "Writing complete. 7757/15286 done.\n",
      "Cycle missing certain parts\n",
      "Writing Cycle 14925057 to csv ...\n",
      "registered 14th FSR cycle\n",
      "Writing complete. 8864/15286 done.\n",
      "Writing Cycle 14925231 to csv ...\n",
      "registered 15th FSR cycle\n",
      "Writing complete. 8865/15286 done.\n",
      "Writing Cycle 14935227 to csv ...\n",
      "registered 16th FSR cycle\n",
      "Writing complete. 8868/15286 done.\n",
      "Writing Cycle 14935557 to csv ...\n",
      "registered 17th FSR cycle\n",
      "Writing complete. 8869/15286 done.\n",
      "Writing Cycle 14942453 to csv ...\n",
      "registered 18th FSR cycle\n",
      "Writing complete. 8874/15286 done.\n",
      "Writing Cycle 14942628 to csv ...\n",
      "registered 19th FSR cycle\n",
      "Writing complete. 8875/15286 done.\n",
      "Writing Cycle 14943015 to csv ...\n",
      "registered 20th FSR cycle\n",
      "Writing complete. 8876/15286 done.\n",
      "Writing Cycle 14944081 to csv ...\n",
      "registered 21th FSR cycle\n",
      "Writing complete. 8877/15286 done.\n",
      "Writing Cycle 14944896 to csv ...\n",
      "registered 22th FSR cycle\n",
      "Writing complete. 8878/15286 done.\n",
      "Writing Cycle 14946975 to csv ...\n",
      "registered 23th FSR cycle\n",
      "Writing complete. 8881/15286 done.\n",
      "Writing Cycle 14947747 to csv ...\n",
      "registered 24th FSR cycle\n",
      "Writing complete. 8882/15286 done.\n",
      "Writing Cycle 14948679 to csv ...\n",
      "registered 25th FSR cycle\n",
      "Writing complete. 8883/15286 done.\n",
      "Writing Cycle 14949366 to csv ...\n",
      "registered 26th FSR cycle\n",
      "Writing complete. 8884/15286 done.\n",
      "Writing Cycle 14949671 to csv ...\n",
      "registered 27th FSR cycle\n",
      "Writing complete. 8885/15286 done.\n",
      "Writing Cycle 15011180 to csv ...\n",
      "registered 28th FSR cycle\n",
      "Writing complete. 11743/15286 done.\n",
      "Writing Cycle 15050624 to csv ...\n",
      "registered 29th FSR cycle\n",
      "Writing complete. 11747/15286 done.\n",
      "Cycle missing certain parts\n",
      "Number of incomplete cycles: 24\n"
     ]
    }
   ],
   "source": [
    "# prepare the full dataset\n",
    "with open('dataset3.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=features)\n",
    "    counter = 0\n",
    "    alarm_counter = 0\n",
    "    missing_parts_counter = 0\n",
    "    total = len(metadata_dict)\n",
    "    for id, meta in metadata_dict.items():\n",
    "        # if counter < 14421:\n",
    "        #     counter += 1\n",
    "        #     continue\n",
    "        if id not in l:\n",
    "            counter += 1\n",
    "            continue\n",
    "        duration = meta[2]\n",
    "        if duration == 0:\n",
    "            counter += 1\n",
    "            continue\n",
    "        target = meta[3]\n",
    "        cycle = cf.fetch_cycle_json(str(int(id)))['cycles']\n",
    "        if cycle == []:\n",
    "            counter += 1\n",
    "            continue\n",
    "        cycle = cycle[0]\n",
    "        if (cycle['has_missing_sections']):\n",
    "            print('Cycle missing certain parts')\n",
    "            missing_parts_counter += 1\n",
    "            counter += 1\n",
    "            continue\n",
    "        print(f'Writing Cycle {id} to csv ...')\n",
    "        cycle = Cycle(duration, cycle)\n",
    "        init = cycle.digital_init()\n",
    "        end = cycle.digital_end()\n",
    "        act_count = cycle.act_count()\n",
    "        first_act = cycle.first_act()\n",
    "        peak, pit = cycle.analog_count_peak_pit()\n",
    "        row = {}\n",
    "        row['FSR_Required'] = target\n",
    "        if (int(target) == 1):\n",
    "            alarm_counter += 1\n",
    "            print(f'registered {alarm_counter}th FSR cycle')\n",
    "        row['cycle_duration'] = duration\n",
    "        row['cycle_type'] = cycle.type\n",
    "        digital_init = {x+'_init': y for x, y in init.items()}\n",
    "        digital_end = {x+'_end': y for x, y in end.items()}\n",
    "        digital_act_count = {x+'_act_count': y for x, y in act_count.items()}\n",
    "        digital_first_act = {x+'_first_act': y for x, y in first_act.items()}\n",
    "        analog_peak = {x+'_peak': y for x, y in peak.items()} \n",
    "        analog_pit = {x+'_pit': y for x, y in pit.items()}\n",
    "        row.update(digital_init)\n",
    "        row.update(digital_end)\n",
    "        row.update(digital_act_count)\n",
    "        row.update(digital_first_act)\n",
    "        row.update(analog_peak)\n",
    "        row.update(analog_pit)\n",
    "        assert (len(init) == len(end) and len(end) == len(act_count) and len(act_count) == len(first_act)), 'digital feature lengths misalign'\n",
    "        writer.writerow(row)\n",
    "        counter += 1\n",
    "        print(f'Writing complete. {counter}/{total} done.')\n",
    "        # break\n",
    "    print(f'Number of incomplete cycles: {missing_parts_counter}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cycle_type': 'PREVAC', 'cycle_duration': 3166.0, 'DLS_act_count': 1.0, 'DOORASW2_act_count': 0.0, 'DOORA_CLSD_act_count': 0.0, 'DOORA_PLK_act_count': 1.0, 'DOORA_SEAL_act_count': 1.0, 'DOORB_PLK_act_count': 0.0, 'DOORB_SEAL_act_count': 0.0, 'NEUT1_SW_act_count': 0.0, 'NEUT2_SW_act_count': 0.0, 'NO_FLOOD_act_count': 0.0, 'S01_act_count': 1.0, 'S02_act_count': 5.0, 'S03_act_count': 6.0, 'S04_act_count': 24.0, 'S07_act_count': 6.0, 'S09_act_count': 311.0, 'S35_act_count': 0.0, 'S37_act_count': 2.0, 'S40_act_count': 1.0, 'S43_act_count': 6.0, 'DLS_init': 0.0, 'DOORASW2_init': 0.0, 'DOORA_CLSD_init': 0.0, 'DOORA_PLK_init': 0.0, 'DOORA_SEAL_init': 0.0, 'DOORB_PLK_init': 0.0, 'DOORB_SEAL_init': 0.0, 'NEUT1_SW_init': 0.0, 'NEUT2_SW_init': 0.0, 'NO_FLOOD_init': 0.0, 'S01_init': 0.0, 'S02_init': 0.0, 'S03_init': 0.0, 'S04_init': 0.0, 'S07_init': 0.0, 'S09_init': 0.0, 'S35_init': 0.0, 'S37_init': 0.0, 'S40_init': 0.0, 'S43_init': 0.0, 'DLS_end': 1.0, 'DOORASW2_end': 0.0, 'DOORA_CLSD_end': 0.0, 'DOORA_PLK_end': 1.0, 'DOORA_SEAL_end': 0.0, 'DOORB_PLK_end': 0.0, 'DOORB_SEAL_end': 0.0, 'NEUT1_SW_end': 0.0, 'NEUT2_SW_end': 0.0, 'NO_FLOOD_end': 0.0, 'S01_end': 0.0, 'S02_end': 0.0, 'S03_end': 1.0, 'S04_end': 0.0, 'S07_end': 0.0, 'S09_end': 1.0, 'S35_end': 0.0, 'S37_end': 1.0, 'S40_end': 1.0, 'S43_end': 0.0, 'DLS_first_act': 1.0132659507264687, 'DOORASW2_first_act': 0.0, 'DOORA_CLSD_first_act': 0.0, 'DOORA_PLK_first_act': 0.007264687302590019, 'DOORA_SEAL_first_act': 0.002526847757422615, 'DOORB_PLK_first_act': 0.0, 'DOORB_SEAL_first_act': 0.0, 'NEUT1_SW_first_act': 1.0069488313329122, 'NEUT2_SW_first_act': 0.0, 'NO_FLOOD_first_act': 0.0, 'S01_first_act': 0.007264687302590019, 'S02_first_act': 0.007264687302590019, 'S03_first_act': 0.05022109917877448, 'S04_first_act': 0.0006317119393556538, 'S07_first_act': 0.007580543272267846, 'S09_first_act': 0.0, 'S35_first_act': 1.0009475679090334, 'S37_first_act': 0.0006317119393556538, 'S40_first_act': 0.007264687302590019, 'S43_first_act': 0.0006317119393556538, 'RRTD_peak': 1.0, 'FXRES_peak': 89.0, 'GRTD_peak': 0.0, 'JRTD_peak': 5.0, 'TSENS_peak': 1.0, 'WRTD_peak': 17.0, 'CRTD_peak': 1.0, 'CPRES_peak': 5.0, 'RRTD_pit': 2.0, 'FXRES_pit': 88.0, 'GRTD_pit': 0.0, 'JRTD_pit': 5.0, 'TSENS_pit': 1.0, 'WRTD_pit': 17.0, 'CRTD_pit': 2.0, 'CPRES_pit': 6.0, 'FSR_Required': 0.0}\n"
     ]
    }
   ],
   "source": [
    "with open('dataset2.csv', 'r', newline='') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    c = 0\n",
    "    for row in reader:\n",
    "        c += 1\n",
    "        # if reader[i][-1] == '1':\n",
    "        #     print('alarm_found')\n",
    "        #     c += 1\n",
    "        if c == 10000:\n",
    "            for key, value in row.items():\n",
    "                if key != 'cycle_type':\n",
    "                    row[key] = float(row[key])\n",
    "            print(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
